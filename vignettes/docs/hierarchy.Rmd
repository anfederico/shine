---
title: "Hierarchical Networks"
vignette: >
  %\VignetteIndexEntry{Hierarchical Networks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(comment="", cache=FALSE)
devtools::load_all(".")
```

Due to the heavy computational requirements for high-dimensional graphical modeling, we learn network hierarchies in paralell on high performance computing platforms. Because some networks are dependent on others (e.g. A network is used as a prior in learning another) we need a reactive workflow to handle all of the processes.

We provide a function for generating [Nextflow](https://www.nextflow.io/) workflows based on your hierarchy. Using Nextflow in this way enables the deployment of flexible and reactive workflows on various high performance computing platforms. This not only simplifies the process of estimating network hierarchies on different cloud/cluster architectures, but it also makes your results reproducible.

This is the last step in learning networks. At this point, you should have identified a network hierarchy, employed a gene selection method, and optionally learned structural constraints for your networks.

# Requirements for Nextflow

Make sure your Java installation is version 8 or higher...
```bash
java -version
```

Create a new directory and install/test Nextflow...
```bash
mkdir nf-test
cd nf-test
curl -s https://get.nextflow.io | bash
./nextflow run hello
```

Alternatively, you can install [Docker](https://docs.docker.com/install/) and pull our [Dockerfile](https://github.com/montilab/shine/packages)...

```
docker run hello-world
docker pull docker.pkg.github.com/montilab/shine/workflow:latest
```

# Terminology

`hierarchy` - A string describing the hierarchy in dot language notation  
`condition` - A column in the expression set phenotype data used to assign samples to different networks  
`eset` - An expression set object containing all samples across multiple networks  
`blanket` - A gene x gene matrix of structural constraints for network learning  
`outdir` - A directory where workflow will be created  
`iter` - The number of iterations for the sampling algorithm  
`cores` - The number of cores for each network to use for parallel execution  

# Example Data

```{r, eval=FALSE}
library(shine)
```

```{r}
data(toy)
```

```{r}
dim(toy)
table(toy$subtype)
```

# Describing Hierarchies

Hierarchies are described using notation for directed graphs described with the [DOT](https://www.graphviz.org/doc/info/lang.html) language. This format is used to describe which parent networks are used as priors for learning child networks. 

*Notes*  
- Groups must be separated by `_` only  
- Group labels cannot contain spaces  
- Only directed notation `->` can be used  

This most simple workflow includes building networks for groups A, B, and C without any prior information.
```{r, fig.width=3, fig.height=1}
condition <- "subtype"
hierarchy <- "
A
B
C
"

plt.hierarchy(hierarchy)
```

Here we first learn the root network - combining samples from groups A, B, and C - and then use this network as a prior for learning each group individually.
```{r, fig.width=3, fig.height=2}
condition <- "subtype"
hierarchy <- "
A_B_C -> A
A_B_C -> B
A_B_C -> C
"

plt.hierarchy(hierarchy)
```

Here is the same as previously, except there are internal nodes which are learned before dependent leaf nodes.
```{r, fig.width=3, fig.height=3}
condition <- "subtype"
hierarchy <- "
A_B_C -> A_B
A_B_C -> C
A_B -> A
A_B -> B
"

plt.hierarchy(hierarchy)
```

# Filtering and Constraints

He we repeat methods detailed in previous sections for variable selection and complexity reduction.
```{r, results='hide'}
# Filter out non-varying genes
genes.filtered <- filter.var(toy, column="subtype", subtypes=c("A", "B", "C"))

# Select top genes by median absolute deviation
genes.selected <- select.var(toy, column="subtype", subtypes=c("A", "B", "C"), genes=genes.filtered, limit=150)

# Subset toy dataset
eset <- toy[genes.selected,]

# Find constraints for structure with zero-order correlations
wgcna <- mods.detect(eset, min.size=5, cores=3, do.plot=FALSE)
metanet <- bdg.metanet(wgcna$eigengenes, cut=0.5, mpl=TRUE, iter=20000, cores=3)

# Set constraints
blanket <- blanket.new(wgcna$genes)
blanket <- blanket.lift(blanket, wgcna$mods, metanet$edges)
```

# Generative Workflows

In summary, a hierarchy of networks must be defined using sample names of a particular condition in the expression set object. If variable selection is required, the expression set should be subset on these variables beforehand. And if structural constraints are used, the rownames and colnames of the blanket matrix should match the selected variables. Once setup, use the following function to generate a reactive workflow based on the hierarchy.
```{r, eval=FALSE}
build.workflow(hierarchy,
               condition,
               eset,
               blanket,
               iter=10000,
               cores=3)
```

Building the workflow results in the creation of a directory with the following contents.

```md
/workflow
 ├── /configs
 ├── /scripts
 ├── /templates
 ├── workflow.config
 ├── workflow.nf
 └── nextflow
```
`/configs` - A directory of inheritable configurations [*]  
`/scripts` - Scripts used by the workflow  
`/templates` - Templates used by the workflow  
`workflow.config` - Workflow configuration file [*]  
`workflow.nf` - Dynamically generated workflow  
`nextflow` - Nextflow executable  

Most files should not be modified, except the configuration files...

### Workflow Configuration

The configuration is quite simple. One option you might want to change is the output of the workflow. This is where the result networks and logs will be saved. If you want an update when the workflow completes, put in your email! You'll likely need to edit the profile configurations, particularly if you are running on a cluster. The local profile will work out of the box, but docker, aws, and sge are popular examples.

```md
profiles {
  local {includeConfig "configs/local.config"}
  docker {includeConfig "configs/docker.config"}
  sge {includeConfig "configs/sge.config"}
  aws {includeConfig "configs/aws.config"}
}

params {
  data = "$baseDir/data/data.rds"
  output = "$baseDir"
  email = ""
}
```

### Workflow Design

This configuration file parameterizes a workflow that looks something like the following example. The learning of each network is described as a process, where some are dependent on others. In this case, processes A, B, and C are dependent on process A_B_C `input: file prior from A_B_C_rds`. Therefore, these processes will not start until A_B_C is finished.

If something goes wrong with process A_B_C, the workflow will only finish other non-dependent processes. Once the user fixes the error, the workflow can be resumed without any loss of progress.

```md
process A_B_C {
    input:
    val include from "A B C"

    output:
    file '*.rds' into A_B_C_rds
}

process A {
    input:
    val include from "A"
    file prior from A_B_C_rds

    output:
    file '*.rds' into A_rds
}

process B {
    input:
    val include from "B"
    file prior from A_B_C_rds

    output:
    file '*.rds' into B_rds
}

process C {
    input:
    val include from "C"
    file prior from A_B_C_rds

    output:
    file '*.rds' into C_rds
}

```
### Workflow Commands

**Run Locally**
```bash
./nextflow workflow.nf -c workflow.config -profile local
```

**Run on Cloud/Cluster**
```bash
./nextflow workflow.nf -c workflow.config -profile sge
```

**Run with Docker Container**  

```bash
./nextflow workflow.nf -c workflow.config -with-docker montilab/shine
```

**Resume Workflow**
```bash
./nextflow workflow.nf -resume -c workflow.config
```

### Output

A successful run should look similar...

```md
N E X T F L O W  ~  version 19.10.0
Launching `workflow.nf` [mad_northcutt] - revision: e7aff2bf48
-
W O R K F L O W ~ Configuration
===============================
data      : /Users/anthonyfederico/Downloads/nextflow/data/data.rds
output    : /Users/anthonyfederico/Downloads/nextflow
-------------------------------

Hierarchy
A_B_C -> A_B
A_B_C -> C
A_B -> A
A_B -> B

-

executor >  local (5)
[4d/715ff1] process > A_B_C [100%] 1 of 1 ✔
[87/c2d03b] process > C     [100%] 1 of 1 ✔
[6b/544fdd] process > A_B   [100%] 1 of 1 ✔
[96/916564] process > A     [100%] 1 of 1 ✔
[43/c599d4] process > B     [100%] 1 of 1 ✔

Completed at: 24-Dec-2019 23:01:05
Duration    : 1m 45s
CPU hours   : 0.1
Succeeded   : 5
```

By default, the networks will be saved individually as `.rds` files within a directory called *networks*...

```md
/nextflow
├── /networks
│   ├── A_B_C.rds
│   ├── A_B.rds
│   ├── A.rds
|   ├── B.rds
|   └── C.rds
|
└── /logs
```

Each network is associated with a log file, which records the parameters and progress of the estimation...

```md
Parameters
Label: A_B
Data: data.rds
Prior: A_B_C.rds
Condition: subtype
Include: A, B
Iter: 10000
Cores: 3

Data: Features  Samples 
      150       20 

Samples: A  B 
         10 10 

Estimate
 Iteration  1                 
 Iteration  406                 
 Iteration  811                 
 Iteration  1201                 
 Iteration  1606                 
 Iteration  2011                 
 Iteration  2401                 
 Iteration  2806                 
 Iteration  3211                 
 Iteration  3601                 
 Iteration  4006                 
 Iteration  4411                 
 Iteration  4801                 
 Iteration  5206                 
 ...
```

Networks are saved as `bdgraph` objects which contain a matrix of posterior edge probabilities as well as the last sampled graph. We can import these networks for analysis directly into [Netviz](https://github.com/montilab/netviz). See the [next section](https://montilab.github.io/shine/articles/docs/netviz.html) for more details.
